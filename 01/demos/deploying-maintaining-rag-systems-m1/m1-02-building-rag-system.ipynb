{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure newer SQLite for ChromaDB compatibility\n",
    "import sys\n",
    "try:\n",
    "    __import__('pysqlite3')\n",
    "    sys.modules['sqlite3'] = sys.modules.pop('pysqlite3')\n",
    "    print(\"✓ Using pysqlite3-binary for SQLite 3.46+\")\n",
    "except ImportError:\n",
    "    import sqlite3\n",
    "    print(f\"⚠️  Using system SQLite {sqlite3.sqlite_version} - may need pysqlite3-binary\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pluralsight Course : Building and Deploying RAG in Production\n",
    "\n",
    "#### Demo: Basic RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install the required libraries\n",
    "!pip install -qqq llama-index llama-index-llms-openai llama-index-vector-stores-chroma\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# Load API key from environment (optionally from a .env file)\n",
    "try:\n",
    "    from dotenv import load_dotenv  # pip install python-dotenv (if not available)\n",
    "    load_dotenv()\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "if not os.getenv(\"OPENAI_API_KEY\"):\n",
    "    raise RuntimeError(\n",
    "        \"OPENAI_API_KEY is not set. Export it in your shell or put it in a .env file.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Embedding and LLM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "# define embeding model \n",
    "embed_model = OpenAIEmbedding()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llms.openai import OpenAI\n",
    "# define LLM model\n",
    "llm = OpenAI(model=\"gpt-4o\", temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import Settings\n",
    "\n",
    "# setting embedding model and llm model globally\n",
    "Settings.embed_model = embed_model\n",
    "Settings.llm = llm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ingestion Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set chunk size\n",
    "Settings.chunk_size = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries \n",
    "from llama_index.core import SimpleDirectoryReader\n",
    "from llama_index.core.node_parser import TokenTextSplitter\n",
    "\n",
    "# load\n",
    "documents = SimpleDirectoryReader(\"data/MovieWatchList/MovieWatchList\").load_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define chunking strategy\n",
    "text_splitter = TokenTextSplitter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to send telemetry event ClientStartEvent: module 'chromadb' has no attribute 'get_settings'\n",
      "Failed to send telemetry event ClientCreateCollectionEvent: module 'chromadb' has no attribute 'get_settings'\n",
      "Failed to send telemetry event ClientCreateCollectionEvent: module 'chromadb' has no attribute 'get_settings'\n"
     ]
    }
   ],
   "source": [
    "# define vector database and store \n",
    "import chromadb\n",
    "from llama_index.vector_stores.chroma import ChromaVectorStore\n",
    "\n",
    "# create local in-memory client\n",
    "chroma_client = chromadb.EphemeralClient()\n",
    "# create a collection\n",
    "chroma_collection = chroma_client.create_collection(\"ps-foo-rag\", get_or_create=True)\n",
    "# define the vector store using the collection\n",
    "vector_store = ChromaVectorStore(chroma_collection=chroma_collection)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current SQLite version: 3.46.1\n",
      "Python sqlite3 module version: 2.6.0\n",
      "✓ SQLite 3.46.1 is compatible with ChromaDB\n"
     ]
    }
   ],
   "source": [
    "# Check current SQLite version (before ChromaDB import)\n",
    "import sqlite3\n",
    "print(f\"Current SQLite version: {sqlite3.sqlite_version}\")\n",
    "print(f\"Python sqlite3 module version: {sqlite3.version}\")\n",
    "\n",
    "# ChromaDB requires SQLite >= 3.35.0\n",
    "required_version = \"3.35.0\"\n",
    "current_version = sqlite3.sqlite_version\n",
    "\n",
    "from packaging import version\n",
    "if version.parse(current_version) < version.parse(required_version):\n",
    "    print(f\"❌ SQLite {current_version} is too old. ChromaDB needs >= {required_version}\")\n",
    "    print(\"Installing pysqlite3-binary to upgrade SQLite...\")\n",
    "else:\n",
    "    print(f\"✓ SQLite {current_version} is compatible with ChromaDB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated SQLite version: 3.46.1\n",
      "Python sqlite3 module version: 2.6.0\n",
      "✓ ChromaDB version: 1.1.0\n",
      "✓ ChromaDB imported successfully with updated SQLite\n"
     ]
    }
   ],
   "source": [
    "# Fix SQLite version compatibility for ChromaDB\n",
    "!pip install -qqq pysqlite3-binary packaging\n",
    "\n",
    "# Now configure to use the newer SQLite\n",
    "import sys\n",
    "__import__('pysqlite3')\n",
    "sys.modules['sqlite3'] = sys.modules.pop('pysqlite3')\n",
    "\n",
    "# Verify the upgrade worked\n",
    "import sqlite3\n",
    "print(f\"Updated SQLite version: {sqlite3.sqlite_version}\")\n",
    "print(f\"Python sqlite3 module version: {sqlite3.version}\")\n",
    "\n",
    "# Now ChromaDB should work\n",
    "import chromadb\n",
    "print(f\"✓ ChromaDB version: {chromadb.__version__}\")\n",
    "print(\"✓ ChromaDB imported successfully with updated SQLite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define ingestion pipeline\n",
    "from llama_index.core.ingestion import IngestionPipeline\n",
    "\n",
    "pipeline = IngestionPipeline(\n",
    "    transformations=[\n",
    "        text_splitter,\n",
    "        embed_model,\n",
    "    ],\n",
    "    vector_store=vector_store,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to send telemetry event CollectionAddEvent: module 'chromadb' has no attribute 'get_settings'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of nodes or chunks : 4\n"
     ]
    }
   ],
   "source": [
    "# run the ingestion pipeline\n",
    "nodes = pipeline.run(documents=documents)\n",
    "print(f\"number of nodes or chunks : {len(nodes)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RAG Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import VectorStoreIndex\n",
    "\n",
    "vector_index = VectorStoreIndex.from_vector_store(\n",
    "    vector_store=vector_store,\n",
    "    embed_model=embed_model,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create semantic query engine \n",
    "vector_query_engine = vector_index.as_query_engine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Movie Watch List Application Documentation\n",
      "\n",
      "## Overview\n",
      "\n",
      "The Movie Watch List application is a web-based platform designed to help users manage and explore their movie watch lists. It integrates with The Movie Database (TMDB) API to fetch movie data and provides an interactive user interface using Razor Components.\n",
      "\n",
      "## Features\n",
      "\n",
      "- **Movie Data Integration**: Connects to TMDB API to retrieve movie information.\n",
      "- **Interactive UI**: Utilizes Razor Components for a dynamic and responsive user experience.\n",
      "- **Environment-Specific Configuration**: Supports different configurations for development and production environments.\n",
      "\n",
      "## Setup Instructions\n",
      "\n",
      "### Prerequisites\n",
      "\n",
      "- .NET SDK installed on your machine.\n",
      "- A valid TMDB API key.\n",
      "\n",
      "### Configuration\n",
      "\n",
      "1. **Clone the Repository**: Clone the application repository to your local machine.\n",
      "\n",
      "2. **API Key Setup**: \n",
      "   - Navigate to the `appsettings.Development.json` file.\n",
      "   - Replace `\"YOUR_TMDB_API_KEY_HERE\"` with your actual TMDB API key.\n",
      "\n",
      "3. **Build and Run the Application**:\n",
      "   - Open a terminal and navigate to the project directory.\n",
      "   - Run the following command to build and start the application:\n",
      "     ```bash\n",
      "     dotnet run\n",
      "     ```\n",
      "\n",
      "### Application Structure\n",
      "\n",
      "The application is structured to use services and components effectively. Below is a class diagram using Mermaid to illustrate the main components and their interactions.\n",
      "\n",
      "```mermaid\n",
      "classDiagram\n",
      "    class WebApplication {\n",
      "        +CreateBuilder(args)\n",
      "        +Build()\n",
      "        +Run()\n",
      "    }\n",
      "\n",
      "    class TmdbClient {\n",
      "        +BaseAddress : Uri\n",
      "    }\n",
      "\n",
      "    class TMDBOptions {\n",
      "        +ApiKey : string\n",
      "    }\n",
      "\n",
      "    class App {\n",
      "        +MapRazorComponents()\n",
      "        +AddInteractiveServerRenderMode()\n",
      "        +AddInteractiveWebAssemblyRenderMode()\n",
      "    }\n",
      "\n",
      "    WebApplication --> TmdbClient : Uses\n",
      "    WebApplication --> TMDBOptions : Configures\n",
      "    WebApplication --> App : Maps Components\n",
      "```\n",
      "\n",
      "## Development and Production\n",
      "\n",
      "- **Development**: The application uses WebAssembly debugging and logs information at the \"Information\" level.\n",
      "- **Production**: It employs an exception handler and HTTP Strict Transport Security (HSTS) for enhanced security.\n",
      "\n",
      "## Additional Notes\n",
      "\n",
      "- Ensure that the application is running in a secure environment, especially in production, by configuring HTTPS and other security measures.\n",
      "- The application is designed to be modular, allowing for easy updates and maintenance.\n"
     ]
    }
   ],
   "source": [
    "# query \n",
    "response = vector_query_engine.query(\"Create markdown documentation taht describes this application and what it does and how to set it up. Please document classes using Mermaid\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Sample Queries to test***\n",
    "\n",
    "- When did Bar started his entrepreneurial journey ?\n",
    "- Who are the co-founders of the company ?\n",
    "- What is the Bar's AI vision?\n",
    "- Who is the CEO of company Foo? and what are the other companies he has started earlier.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
