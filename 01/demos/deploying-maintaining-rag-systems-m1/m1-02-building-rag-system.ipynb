{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pluralsight Course : Building and Deploying RAG in Production\n",
    "\n",
    "#### Demo: Basic RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install the required libraries\n",
    "!pip install -qqq llama-index llama-index-llms-openai llama-index-vector-stores-chroma\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# Load API key from environment (optionally from a .env file)\n",
    "try:\n",
    "    from dotenv import load_dotenv  # pip install python-dotenv (if not available)\n",
    "    load_dotenv()\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "if not os.getenv(\"OPENAI_API_KEY\"):\n",
    "    raise RuntimeError(\n",
    "        \"OPENAI_API_KEY is not set. Export it in your shell or put it in a .env file.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Embedding and LLM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "# define embeding model \n",
    "embed_model = OpenAIEmbedding()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llms.openai import OpenAI\n",
    "# define LLM model\n",
    "llm = OpenAI(model=\"gpt-4o\", temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import Settings\n",
    "\n",
    "# setting embedding model and llm model globally\n",
    "Settings.embed_model = embed_model\n",
    "Settings.llm = llm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ingestion Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set chunk size\n",
    "Settings.chunk_size = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries \n",
    "from llama_index.core import SimpleDirectoryReader\n",
    "from llama_index.core.node_parser import TokenTextSplitter\n",
    "\n",
    "# load\n",
    "documents = SimpleDirectoryReader(\"data\").load_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define chunking strategy\n",
    "text_splitter = TokenTextSplitter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "An instance of Chroma already exists for ephemeral with different settings",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mllama_index\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvector_stores\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mchroma\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ChromaVectorStore\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# create local in-memory client\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m chroma_client \u001b[38;5;241m=\u001b[39m \u001b[43mchromadb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEphemeralClient\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# create a collection\u001b[39;00m\n\u001b[1;32m      8\u001b[0m chroma_collection \u001b[38;5;241m=\u001b[39m chroma_client\u001b[38;5;241m.\u001b[39mcreate_collection(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mps-foo-rag\u001b[39m\u001b[38;5;124m\"\u001b[39m, get_or_create\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/chromadb/__init__.py:140\u001b[0m, in \u001b[0;36mEphemeralClient\u001b[0;34m(settings, tenant, database)\u001b[0m\n\u001b[1;32m    137\u001b[0m tenant \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(tenant)\n\u001b[1;32m    138\u001b[0m database \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(database)\n\u001b[0;32m--> 140\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mClientCreator\u001b[49m\u001b[43m(\u001b[49m\u001b[43msettings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msettings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtenant\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtenant\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatabase\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdatabase\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/chromadb/api/client.py:65\u001b[0m, in \u001b[0;36mClient.__init__\u001b[0;34m(self, tenant, database, settings)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m     61\u001b[0m     tenant: Optional[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m DEFAULT_TENANT,\n\u001b[1;32m     62\u001b[0m     database: Optional[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m DEFAULT_DATABASE,\n\u001b[1;32m     63\u001b[0m     settings: Settings \u001b[38;5;241m=\u001b[39m Settings(),\n\u001b[1;32m     64\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msettings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msettings\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m tenant \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     67\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtenant \u001b[38;5;241m=\u001b[39m tenant\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/chromadb/api/shared_system_client.py:19\u001b[0m, in \u001b[0;36mSharedSystemClient.__init__\u001b[0;34m(self, settings)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m     16\u001b[0m     settings: Settings \u001b[38;5;241m=\u001b[39m Settings(),\n\u001b[1;32m     17\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_identifier \u001b[38;5;241m=\u001b[39m SharedSystemClient\u001b[38;5;241m.\u001b[39m_get_identifier_from_settings(settings)\n\u001b[0;32m---> 19\u001b[0m     \u001b[43mSharedSystemClient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_system_if_not_exists\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_identifier\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msettings\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/chromadb/api/shared_system_client.py:38\u001b[0m, in \u001b[0;36mSharedSystemClient._create_system_if_not_exists\u001b[0;34m(cls, identifier, settings)\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[38;5;66;03m# For now, the settings must match\u001b[39;00m\n\u001b[1;32m     37\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m previous_system\u001b[38;5;241m.\u001b[39msettings \u001b[38;5;241m!=\u001b[39m settings:\n\u001b[0;32m---> 38\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m     39\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn instance of Chroma already exists for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00midentifier\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m with different settings\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     40\u001b[0m         )\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_identifier_to_system[identifier]\n",
      "\u001b[0;31mValueError\u001b[0m: An instance of Chroma already exists for ephemeral with different settings"
     ]
    }
   ],
   "source": [
    "# define vector database and store \n",
    "import chromadb\n",
    "from llama_index.vector_stores.chroma import ChromaVectorStore\n",
    "\n",
    "# create local in-memory client\n",
    "chroma_client = chromadb.EphemeralClient()\n",
    "# create a collection\n",
    "chroma_collection = chroma_client.create_collection(\"ps-foo-rag\", get_or_create=True)\n",
    "# define the vector store using the collection\n",
    "vector_store = ChromaVectorStore(chroma_collection=chroma_collection)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define ingestion pipeline\n",
    "from llama_index.core.ingestion import IngestionPipeline\n",
    "\n",
    "pipeline = IngestionPipeline(\n",
    "    transformations=[\n",
    "        text_splitter,\n",
    "        embed_model,\n",
    "    ],\n",
    "    vector_store=vector_store,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to send telemetry event CollectionAddEvent: module 'chromadb' has no attribute 'get_settings'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of nodes or chunks : 7\n"
     ]
    }
   ],
   "source": [
    "# run the ingestion pipeline\n",
    "nodes = pipeline.run(documents=documents)\n",
    "print(f\"number of nodes or chunks : {len(nodes)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RAG Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import VectorStoreIndex\n",
    "\n",
    "vector_index = VectorStoreIndex.from_vector_store(\n",
    "    vector_store=vector_store,\n",
    "    embed_model=embed_model,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create semantic query engine \n",
    "vector_query_engine = vector_index.as_query_engine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```markdown\n",
      "### Timeline Summary of Bar and Qux\n",
      "\n",
      "- **1998**: Bar launches his first venture, Cam, a tech start-up focused on data management.\n",
      "- **2000**: Bar founds Tres, a company providing cloud-based solutions for small businesses.\n",
      "- **2009**: Bar begins laying the groundwork for Foo, researching the market and developing a business plan.\n",
      "- **Early 2010**: Bar officially founds Foo, with Qux joining as co-founder.\n",
      "- **November 2010**: Foo's website goes live, offering a curated selection of adventure gear.\n",
      "- **2015**: Foo establishes itself as a leading player in the online adventure gear market.\n",
      "```\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# query \n",
    "response = vector_query_engine.query(\"provide a markdown summary of the two men's timeline.\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Sample Queries to test***\n",
    "\n",
    "- When did Bar started his entrepreneurial journey ?\n",
    "- Who are the co-founders of the company ?\n",
    "- What is the Bar's AI vision?\n",
    "- Who is the CEO of company Foo? and what are the other companies he has started earlier.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
